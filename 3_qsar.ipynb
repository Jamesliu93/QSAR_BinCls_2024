{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic libraries ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# === Oversample ===\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce9131-f039-4eb0-8040-8c17fd553f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classifiers ===\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, DMatrix, train\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# === Neural networks from Pytorch Lightning ===\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "# === Metrics and cross-validation ====\n",
    "import logging\n",
    "import warnings\n",
    "from sklearn import metrics as met\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut, KFold\n",
    "\n",
    "\n",
    "# === Check for GPU ===\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2306fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Set project ===\n",
    "proj = 'LSI'\n",
    "proj = 'RS'\n",
    "\n",
    "# === Read Xy ===\n",
    "with open('temp_out/'+proj+'_vars.pkl','rb') as f:\n",
    "    X, y, Xs, Xis, Xsr, Xisr, Xs_pd = pickle.load(f)\n",
    "\n",
    "# === Set up oversampler ===\n",
    "oversample = False\n",
    "ovs = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Reduce verbosity ===\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", \".*set a lower value*\")\n",
    "\n",
    "# === Convert to torch tensors ===\n",
    "def to_tensor(X_trn, y_trn, X_tst, y_tst):\n",
    "    X_trn = torch.tensor(X_trn, dtype=torch.float32)\n",
    "    y_trn = torch.tensor(y_trn, dtype=torch.int32).reshape(-1, 1)\n",
    "    X_tst = torch.tensor(X_tst, dtype=torch.float32)\n",
    "    y_tst = torch.tensor(y_tst, dtype=torch.int32).reshape(-1, 1)\n",
    "    return X_trn, y_trn, X_tst, y_tst\n",
    "\n",
    "# === Lightning module for MLP ===\n",
    "class rscls_mlp(L.LightningModule):\n",
    "    \n",
    "    def __init__(self, xsh: int, ehl: bool, width: int):\n",
    "        super().__init__()\n",
    "        self.dr = nn.Dropout(p=0.2)\n",
    "        self.l1 = nn.Linear(xsh, width)\n",
    "        self.l2 = nn.Linear(width, width)\n",
    "        if ehl:\n",
    "            self.l3 = nn.Sequential(nn.Linear(width, width), nn.ReLU())\n",
    "        else:\n",
    "            self.l3 = nn.Sequential()\n",
    "        self.out = nn.Linear(width, 1)\n",
    "        self.rla = nn.ReLU()\n",
    "        self.net = nn.Sequential(self.dr, self.l1, self.rla, self.l2, self.rla, self.l3, self.out)\n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.dr(x)\n",
    "        # x = self.a1(self.l1(x))\n",
    "        # x = self.a2(self.l2(x))\n",
    "        # x = self.out(x)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.BCEWithLogitsLoss()\n",
    "        loss = loss(logits, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = nn.BCEWithLogitsLoss()\n",
    "        loss = loss(logits, y.float())\n",
    "        self.log('val_loss', loss)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        #avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        #tensorboard_logs = {'val_loss': avg_loss}\n",
    "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", epoch_average)\n",
    "        self.validation_step_outputs.clear()\n",
    "        #return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cross validation function ===\n",
    "def qsar_cv(X, y, n, m, p1, p2, p3, nspl=5, oversample=False):\n",
    "    xsh = np.shape(X)[1]\n",
    "    # === Initialize metrtics and iterator ===\n",
    "    acc, pre, rec, f1s = (np.zeros(nspl*n) for i in range(4))\n",
    "    i = 0\n",
    "    # === Start stopwatch ===\n",
    "    t_sta = time.perf_counter()\n",
    "    \n",
    "    # === Loop over n random seeds ===\n",
    "    ytst_cv = []\n",
    "    prob_cv = []\n",
    "    for rs in range(n):\n",
    "        # === Initialize k-fold cross validation ===\n",
    "        kfold = KFold(n_splits=nspl, shuffle=True, random_state=np.random.seed(rs))\n",
    "        # === Set model ===\n",
    "        if m == 'LR':\n",
    "            model = LogisticRegression(solver=p1, random_state=np.random.seed(rs), max_iter=200)\n",
    "        if m == 'SVM':\n",
    "            model = svm.SVC(kernel=p1, random_state=np.random.seed(rs), probability=True, max_iter=200)\n",
    "        if m == 'RF':\n",
    "            model = RandomForestClassifier(n_estimators=p1, max_depth=p2, random_state=np.random.seed(rs))\n",
    "        if m == 'GBT':\n",
    "            model = XGBClassifier(max_depth=p1, seed=rs)\n",
    "        if m == 'PFN':\n",
    "            model = TabPFNClassifier(device='cpu')\n",
    "        if m == 'MLP':\n",
    "            # === Use GPU if available, else use CPU ===\n",
    "            device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "            seed_everything(rs)\n",
    "            model = rscls_mlp(xsh=xsh, ehl=p1, width=p2).to(device)\n",
    "        \n",
    "        for trn_i, tst_i in kfold.split(X):\n",
    "            # === Split data ===\n",
    "            X_trn, X_tst = X[trn_i], X[tst_i]\n",
    "            y_trn, y_tst = y[trn_i], y[tst_i]\n",
    "            # === Oversample ===\n",
    "            if oversample == True:\n",
    "                X_trn, y_trn = ovs.fit_resample(X_trn, y_trn)\n",
    "            \n",
    "            # === Fit and predict ===\n",
    "            if m == 'MLP':\n",
    "                # === Dataloaders ===\n",
    "                X_trn, y_trn, X_tst, y_tst = to_tensor(X_trn, y_trn, X_tst, y_tst)\n",
    "                trainset = torch.utils.data.TensorDataset(X_trn, y_trn)\n",
    "                testset = torch.utils.data.TensorDataset(X_tst, y_tst)\n",
    "                trn_load = DataLoader(trainset, persistent_workers=True, num_workers=12, batch_size=32, shuffle=True)\n",
    "                tst_load = DataLoader(testset, persistent_workers=True, num_workers=12, batch_size=32, shuffle=False)\n",
    "                trainer = L.Trainer(max_epochs=100, deterministic=True,\n",
    "                                    enable_model_summary=False, enable_progress_bar=True,\n",
    "                                    num_sanity_val_steps=0, limit_val_batches=0)\n",
    "                trainer.fit(model, trn_load, tst_load)\n",
    "                prob = trainer.predict(model, X_tst)\n",
    "                prob = torch.cat(prob).numpy()\n",
    "                pred = (prob >= 0.5).astype(int)\n",
    "            else:\n",
    "                model.fit(X_trn, y_trn.ravel())\n",
    "                prob = model.predict_proba(X_tst)[:,1]\n",
    "                pred = model.predict(X_tst)\n",
    "            \n",
    "            # === Append for performance curves ===\n",
    "            ytst_cv.append(y_tst)\n",
    "            prob_cv.append(prob)\n",
    "            \n",
    "            # === Calculate metrics ===\n",
    "            acc[i] = met.accuracy_score(y_tst,pred)\n",
    "            pre[i] = met.precision_score(y_tst,pred)\n",
    "            rec[i] = met.recall_score(y_tst,pred)\n",
    "            f1s[i] = met.f1_score(y_tst,pred)\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "    # === Stop stopwatch ===\n",
    "    t_end = time.perf_counter()\n",
    "    t_ela = t_end-t_sta\n",
    "\n",
    "    # === Average metrics ===\n",
    "    m_acc = np.mean(acc)\n",
    "    m_pre = np.mean(pre)\n",
    "    m_rec = np.mean(rec)\n",
    "    m_f1s = np.mean(f1s)\n",
    "    ytst_cv = np.concatenate(ytst_cv)\n",
    "    prob_cv = np.concatenate(prob_cv)\n",
    "    prc = met.precision_recall_curve(ytst_cv, prob_cv)\n",
    "    roc = met.roc_curve(ytst_cv, prob_cv)\n",
    "    \n",
    "    ret = {'Model':m, 'Param_1':p1, 'Param_2':p2, 'Param_3':p3, 'Accuracy':m_acc, 'Precision':m_pre, 'Recall':m_rec, 'F1_Score':m_f1s, 'Time':t_ela}\n",
    "    return ret, prc, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Retrieve processed data ===\n",
    "# I: Imputed\n",
    "# S: Scaled\n",
    "# O: Oversampled\n",
    "# R: Reduced\n",
    "def get_X(i):\n",
    "    if i == 0:\n",
    "        return Xs, 'S'\n",
    "    if i == 1:\n",
    "        return Xis, 'IS'\n",
    "    if i == 2:\n",
    "        return Xsr, 'SR'\n",
    "    if i == 3:\n",
    "        return Xisr, 'ISR'\n",
    "\n",
    "# === Initialize metrics dataframe ===\n",
    "metrics = pd.DataFrame(columns=['Model', 'Param_1', 'Param_2', 'Param_3', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Time', 'Data'])\n",
    "prc_m = pd.DataFrame(columns=['P', 'R', 'M'])\n",
    "roc_m = pd.DataFrame(columns=['F', 'T', 'M'])\n",
    "\n",
    "# === PRC and ROC processing function ===\n",
    "def prc_roc(prc, roc, lab):\n",
    "    prc2 = pd.DataFrame(prc[0:2]).transpose()\n",
    "    prc2.columns = ['P', 'R']\n",
    "    prc2['M'] = [lab]*len(prc[0])\n",
    "    roc2 = pd.DataFrame(roc[0:2]).transpose()\n",
    "    roc2.columns = ['F', 'T']\n",
    "    roc2['M'] = [lab]*len(roc[0])\n",
    "    return prc2, roc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b022c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define parameter loops ===\n",
    "def zeroparam(X, y, dt, m, metrics, prc_m, roc_m, oversample):\n",
    "    if oversample == True:\n",
    "        dt = dt+'O'\n",
    "    os, prc, roc = qsar_cv(X, y, 10, m, 0, 0, 0, oversample=oversample)\n",
    "    os['Data']=dt\n",
    "    os = pd.DataFrame(os, index=[0])\n",
    "    # === Append to metrics records ===\n",
    "    metrics = pd.concat([metrics, os], axis=0, ignore_index=True)\n",
    "    prc2, roc2 = prc_roc(prc, roc, m+'.'+dt+'._')\n",
    "    prc_m = pd.concat([prc_m, prc2], axis=0, ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m, roc2], axis=0, ignore_index=True)\n",
    "    return metrics, prc_m, roc_m\n",
    "\n",
    "def oneparam(X, y, dt, m, p1l, metrics, prc_m, roc_m, oversample):\n",
    "    if oversample == True:\n",
    "        dt = dt+'O'\n",
    "    # === Get length of parameter 1 list ===\n",
    "    ll1 = len(p1l)\n",
    "    for i in range(ll1):\n",
    "        # === Get outputs from cross validation ===\n",
    "        os, prc, roc = qsar_cv(X, y, 10, m, p1l[i], 0, 0, oversample=oversample)\n",
    "        os['Data']=dt\n",
    "        os = pd.DataFrame(os, index=[i])\n",
    "        # === Append to metrics records ===\n",
    "        metrics = pd.concat([metrics, os], axis=0, ignore_index=True)\n",
    "        prc2, roc2 = prc_roc(prc, roc, m+'.'+dt+'.'+str(p1l[i]))\n",
    "        prc_m = pd.concat([prc_m, prc2], axis=0, ignore_index=True)\n",
    "        roc_m = pd.concat([roc_m, roc2], axis=0, ignore_index=True)\n",
    "        print(p1l[i])\n",
    "    return metrics, prc_m, roc_m\n",
    "\n",
    "def twoparam(X, y, dt, m, p1l, p2l, metrics, prc_m, roc_m, oversample):\n",
    "    if oversample == True:\n",
    "        dt = dt+'O'\n",
    "    ll1 = len(p1l)\n",
    "    ll2 = len(p2l)\n",
    "    for i in range(ll1):\n",
    "        for j in range(ll2):\n",
    "            os, prc, roc = qsar_cv(X, y, 10, m, p1l[i], p2l[j], 0, oversample=oversample)\n",
    "            os['Data']=dt\n",
    "            os = pd.DataFrame(os, index=[i*ll2+j])\n",
    "            metrics = pd.concat([metrics, os], axis=0, ignore_index=True)\n",
    "            prc2, roc2 = prc_roc(prc, roc, m+'.'+dt+'.'+str(p1l[i])+'.'+str(p2l[j]))\n",
    "            prc_m = pd.concat([prc_m, prc2], axis=0, ignore_index=True)\n",
    "            roc_m = pd.concat([roc_m, roc2], axis=0, ignore_index=True)\n",
    "            print(str(p1l[i])+', '+str(p2l[j]))\n",
    "    return metrics, prc_m, roc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b33da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Logistic regression ===\n",
    "p1l = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
    "for a in range(4):\n",
    "    X, dt = get_X(a)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'LR', p1l, metrics, prc_m, roc_m, oversample=False)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'LR', p1l, metrics, prc_m, roc_m, oversample=True)\n",
    "\n",
    "print('LR complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Support vector machines ===\n",
    "p1l = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "ll1 = len(p1l)\n",
    "for a in range(4):\n",
    "    X, dt = get_X(a)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'SVM', p1l, metrics, prc_m, roc_m, oversample=False)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'SVM', p1l, metrics, prc_m, roc_m, oversample=True)\n",
    "\n",
    "print('SVM complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8482393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Random forest ===\n",
    "p1l = [50, 100, 300]\n",
    "p2l = [5, 10]\n",
    "for a in range(4):\n",
    "    X, dt = get_X(a)\n",
    "    metrics, prc_m, roc_m = twoparam(X, y, dt, 'RF', p1l, p2l, metrics, prc_m, roc_m, oversample=False)\n",
    "    metrics, prc_m, roc_m = twoparam(X, y, dt, 'RF', p1l, p2l, metrics, prc_m, roc_m, oversample=True)\n",
    "\n",
    "print('RF complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gradient boosted trees ===\n",
    "p1l = [3, 5, 10]\n",
    "for a in range(4):\n",
    "    X, dt = get_X(a)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'GBT', p1l, metrics, prc_m, roc_m, oversample=False)\n",
    "    metrics, prc_m, roc_m = oneparam(X, y, dt, 'GBT', p1l, metrics, prc_m, roc_m, oversample=True)\n",
    "\n",
    "print('GBT complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a421671-5679-4f41-aab7-14647463f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prior-Data Fitted Networks ===\n",
    "X, dt = get_X(2)\n",
    "metrics, prc_m, roc_m = zeroparam(X, y, dt, 'PFN', metrics, prc_m, roc_m, oversample=False)\n",
    "metrics, prc_m, roc_m = zeroparam(X, y, dt, 'PFN', metrics, prc_m, roc_m, oversample=True)\n",
    "X, dt = get_X(3)\n",
    "metrics, prc_m, roc_m = zeroparam(X, y, dt, 'PFN', metrics, prc_m, roc_m, oversample=False)\n",
    "metrics, prc_m, roc_m = zeroparam(X, y, dt, 'PFN', metrics, prc_m, roc_m, oversample=True)\n",
    "\n",
    "print('PFN complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Multilayer perceptron ===\n",
    "p1l = [False, True]\n",
    "p2l = [20, 40]\n",
    "for a in range(4):\n",
    "    X, dt = get_X(a)\n",
    "    metrics, prc_m, roc_m = twoparam(X, y, dt, 'MLP', p1l, p2l, metrics, prc_m, roc_m, oversample=False)\n",
    "    metrics, prc_m, roc_m = twoparam(X, y, dt, 'MLP', p1l, p2l, metrics, prc_m, roc_m, oversample=True)\n",
    "    \n",
    "print('MLP complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Write metrics to file ===\n",
    "metrics.to_csv(proj+'_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "prc_m.to_csv(proj+'_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "roc_m.to_csv(proj+'_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82858f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a91dad-dad5-4340-b6f0-ed6c78ef4a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
