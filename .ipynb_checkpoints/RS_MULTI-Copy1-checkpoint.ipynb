{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9c11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic libraries ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# === Feature generation ===\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn import preprocessing as pp\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# === Classifiers ===\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, cv, DMatrix\n",
    "\n",
    "# === Metrics and cross-validation ====\n",
    "from sklearn import metrics as met\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut, KFold\n",
    "\n",
    "# === Neural networks ===\n",
    "import tensorflow as tf\n",
    "from keras import Model, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb88f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# === Read in files with X,Y ===\n",
    "RS_XY = pd.read_csv('rsxy_v1.csv')\n",
    "clist = list(RS_XY['SMILES'])\n",
    "y = np.array(RS_XY['Sens'])\n",
    "y = np.reshape(y,(-1,1))\n",
    "yr = y.ravel()\n",
    "X = np.zeros(shape=(len(clist),1826))\n",
    "\n",
    "# === Calculate descriptors ===\n",
    "calc = Calculator(descriptors)\n",
    "dlist = list(calc._name_dict.keys())\n",
    "for i in range(len(clist)):\n",
    "    mol = Chem.MolFromSmiles(clist[i])\n",
    "    X[i,:] = calc(mol)\n",
    "sh1 = np.shape(X)\n",
    "print(f'Shape | raw: {sh1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11caa4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Filter data and scale ===\n",
    "X0 = X\n",
    "X = X[:,~np.any(np.isnan(X), axis=0)]\n",
    "X = X[:, np.var(X, axis=0) != 0]\n",
    "scaler = pp.MinMaxScaler().fit(X)\n",
    "Xs = scaler.transform(X)\n",
    "sh2 = np.shape(Xs)\n",
    "print(f'Shape | filtered/scaled: {sh2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Filter data and scale ===\n",
    "X2 = pd.DataFrame(X0, columns=dlist)\n",
    "X2.to_csv('temp_out/X.csv', header=True)\n",
    "X2 = X2.dropna(axis=1)\n",
    "X2 = X2.loc[:, X2.var()!=0]\n",
    "X2.shape\n",
    "X2.to_csv('temp_out/Xs.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17952878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Heatmap of feature correlation ===\n",
    "Xs_pd = pd.DataFrame(Xs)\n",
    "hm1 = sns.heatmap(Xs_pd.corr())\n",
    "hm1.figure.savefig('temp_out/Xs.tiff',dpi=300,pil_kwargs={\"compression\": \"tiff_lzw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401449b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Conduct PCA and display updated heatmap ===\n",
    "pca = PCA(n_components=50,random_state=np.random.seed(0))\n",
    "pca.fit(Xs_pd)\n",
    "Xr = pca.transform(Xs_pd)\n",
    "Xr_pd = pd.DataFrame(Xr)\n",
    "hm2 = sns.heatmap(Xr_pd.corr())\n",
    "hm2.figure.savefig('temp_out/Xr.tiff',dpi=300,pil_kwargs={\"compression\": \"tiff_lzw\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define creation of artificial neural network ===\n",
    "def create_ann(d,l):\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(l,)))\n",
    "    model.add(Dropout(d,input_shape=(l,)))\n",
    "    model.add(Dense(50,activation='relu',name='hl_2',kernel_regularizer=tf.keras.regularizers.L1(0)))\n",
    "    model.add(Dense(25,activation='relu',name='hl_3',kernel_regularizer=tf.keras.regularizers.L1(0)))\n",
    "    model.add(Dense(1,activation='linear',name='l_o',kernel_regularizer=tf.keras.regularizers.L1(0)))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cross validation function ===\n",
    "def qsar_cv(X,y,n,m,p1,p2,p3):\n",
    "\n",
    "    acc, pre, rec, f1s, auc = (np.zeros(n) for i in range(5))\n",
    "    t_sta = time.perf_counter()\n",
    "    \n",
    "    for i in range(n):\n",
    "        if m == 'LR':\n",
    "            model = LogisticRegression(solver=p1,random_state=np.random.seed(i),max_iter=200)\n",
    "        if m == 'SVM':\n",
    "            model = svm.SVC(kernel=p1,random_state=np.random.seed(i),probability=True)\n",
    "        if m == 'RF':\n",
    "            model = RandomForestClassifier(n_estimators=p1,max_depth=p2,random_state=np.random.seed(i))\n",
    "        if m == 'GBT':\n",
    "            model = XGBClassifier(max_depth=p1,seed=i)\n",
    "        prob = cross_val_predict(model, X, y, method='predict_proba')[:,1]\n",
    "        pred = cross_val_predict(model, X, y, method='predict')\n",
    "    \n",
    "        acc[i] = met.accuracy_score(y,pred)\n",
    "        pre[i] = met.precision_score(y,pred)\n",
    "        rec[i] = met.recall_score(y,pred)\n",
    "        f1s[i] = met.f1_score(y,pred)\n",
    "        \n",
    "        auc[i] = met.roc_auc_score(y,prob,average='micro')\n",
    "        prc = met.precision_recall_curve(y,prob)\n",
    "        roc = met.roc_curve(y,prob)\n",
    "\n",
    "    t_end = time.perf_counter()\n",
    "    t_ela = t_end-t_sta\n",
    "\n",
    "    m_acc = np.mean(acc)\n",
    "    m_pre = np.mean(pre)\n",
    "    m_rec = np.mean(rec)\n",
    "    m_f1s = np.mean(f1s)\n",
    "    m_auc = np.mean(roc)\n",
    "    \n",
    "    ret = {'Model':m, 'Param_1':p1, 'Param_2':p2, 'Param_3':p3, 'Accuracy':m_acc, 'Precision':m_pre, 'Recall':m_rec, 'F1_Score':m_f1s, 'ROC_AUC':m_auc, 'Time':t_ela}\n",
    "    return ret, prc, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Artificial neural network cross validation ===\n",
    "def qsar_ann_cv(X, y, nspl, nsed, p1, p2, p3):\n",
    "\n",
    "    # === Accumulate accuracy ===\n",
    "    acc, pre, rec, f1s, auc = (np.zeros(nspl*nsed) for i in range(5))\n",
    "    i = 0\n",
    "\n",
    "    # === K-fold cross validation ===\n",
    "    t_sta = time.perf_counter()\n",
    "    kfold = KFold(n_splits=nspl, shuffle=True, random_state=42)\n",
    "    for rs in range(nsed):\n",
    "        tf.keras.utils.set_random_seed(rs)\n",
    "        for trn_i, tst_i in kfold.split(X):\n",
    "    \n",
    "            # === Split data ===\n",
    "            X_trn, X_tst = X[trn_i], X[tst_i]\n",
    "            y_trn, y_tst = y[trn_i], y[tst_i]\n",
    "\n",
    "            # === Create and train model ===\n",
    "            model = create_ann(p2,np.shape(X)[1])\n",
    "            model.fit(X_trn, y_trn, epochs=p1, verbose=0)\n",
    "\n",
    "            # === Make predictions ===\n",
    "            yh_tst = model.predict(X_tst)\n",
    "            \n",
    "            auc[i] = met.roc_auc_score(y_tst,yh_tst,average='micro')\n",
    "            prc = met.precision_recall_curve(y_tst,yh_tst)\n",
    "            roc = met.roc_curve(y_tst,yh_tst)\n",
    "            \n",
    "            yh_tst = (yh_tst >= 0.5).astype(int)\n",
    "        \n",
    "            acc[i] = met.accuracy_score(y_tst,yh_tst)\n",
    "            pre[i] = met.precision_score(y_tst,yh_tst)\n",
    "            rec[i] = met.recall_score(y_tst,yh_tst)\n",
    "            f1s[i] = met.f1_score(y_tst,yh_tst)\n",
    "            auc[i] = met.roc_auc_score(y_tst,yh_tst)\n",
    "\n",
    "            i += 1\n",
    "        print(f'Completed seed {rs}.')\n",
    "\n",
    "    t_end = time.perf_counter()\n",
    "    t_ela = t_end-t_sta\n",
    "    \n",
    "    m_acc = np.mean(acc)\n",
    "    m_pre = np.mean(pre)\n",
    "    m_rec = np.mean(rec)\n",
    "    m_f1s = np.mean(f1s)\n",
    "    m_auc = np.mean(auc)\n",
    "    \n",
    "    ret = {'Model':'ANN', 'Param_1':p1, 'Param_2':p2, 'Param_3':p3, 'Accuracy':m_acc, 'Precision':m_pre, 'Recall':m_rec, 'F1_Score':m_f1s, 'ROC_AUC':m_auc, 'Time':t_ela}\n",
    "    return ret,prc,roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initialize metrics dataframe ===\n",
    "metrics = pd.DataFrame(columns=['Model', 'Param_1', 'Param_2', 'Param_3', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC', 'Time', 'Data'])\n",
    "prc_m = pd.DataFrame(columns=['P','R','M'])\n",
    "roc_m = pd.DataFrame(columns=['F','T','M'])\n",
    "\n",
    "# === PRC and ROC processing function ===\n",
    "def prc_roc(prc,roc,lab):\n",
    "    prc2 = pd.DataFrame(prc[0:2]).transpose()\n",
    "    prc2.columns = ['P','R']\n",
    "    prc2['M'] = [lab]*len(prc[0])\n",
    "    roc2 = pd.DataFrame(roc[0:2]).transpose()\n",
    "    roc2.columns = ['F','T']\n",
    "    roc2['M'] = [lab]*len(roc[0])\n",
    "    return prc2,roc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b33da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logistic regression and support vector machines ===\n",
    "p1l = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xs,yr,100,'LR',p1l[i],0,0)\n",
    "    os['Data']='Scaled'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'LR.S.'+p1l[i])\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "p1l = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xr,yr,100,'LR',p1l[i],0,0)\n",
    "    os['Data']='Reduced'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'LR.R.'+p1l[i])\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "print('LR complete')\n",
    "    \n",
    "p1l = ['linear', 'poly', 'rbf']\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xs,yr,100,'SVM',p1l[i],0,0)\n",
    "    os['Data']='Scaled'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'SVM.S.'+p1l[i])\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "p1l = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xr,yr,100,'SVM',p1l[i],0,0)\n",
    "    os['Data']='Reduced'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'SVM.R.'+p1l[i])\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "print('SVM complete')\n",
    "\n",
    "metrics.to_csv('RS_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "#prc_m.to_csv('RS_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "#roc_m.to_csv('RS_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8482393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Random forest ===\n",
    "p1l = [50, 100, 300]\n",
    "p2l = [5, 10]\n",
    "ll1 = len(p1l)\n",
    "ll2 = len(p2l)\n",
    "for i in range(ll1):\n",
    "    for j in range(ll2):\n",
    "        os,prc,roc = qsar_cv(Xs,yr,100,'RF',p1l[i],p2l[j],0)\n",
    "        os['Data']='Scaled'\n",
    "        os = pd.DataFrame(os,index=[i*ll2+j])\n",
    "        metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "        prc2,roc2 = prc_roc(prc,roc,'RF.S.'+str(p1l[i])+'.'+str(p2l[j]))\n",
    "        prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "        roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "        print(i*ll2+j)\n",
    "for i in range(ll1):\n",
    "    for j in range(ll2):\n",
    "        os,prc,roc = qsar_cv(Xr,yr,100,'RF',p1l[i],p2l[j],0)\n",
    "        os['Data']='Reduced'\n",
    "        os = pd.DataFrame(os,index=[i*ll2+j])\n",
    "        metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "        prc2,roc2 = prc_roc(prc,roc,'RF.R.'+str(p1l[i])+'.'+str(p2l[j]))\n",
    "        prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "        roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "        print(i*ll2+j)\n",
    "print('RF complete')\n",
    "\n",
    "metrics.to_csv('RS_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "#prc_m.to_csv('RS_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "#roc_m.to_csv('RS_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gradient boosted trees ===\n",
    "p1l = [3, 5, 10]\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xs,yr,100,'GBT',p1l[i],0,0)\n",
    "    os['Data']='Scaled'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'GBT.S.'+str(p1l[i]))\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "for i in range(ll1):\n",
    "    os,prc,roc = qsar_cv(Xr,yr,100,'GBT',p1l[i],0,0)\n",
    "    os['Data']='Reduced'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'GBT.R.'+str(p1l[i]))\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "    print(p1l[i])\n",
    "print('GBT complete')\n",
    "\n",
    "metrics.to_csv('RS_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "#prc_m.to_csv('RS_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "#roc_m.to_csv('RS_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830df4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Artificial neural networks ===\n",
    "p1l = [100, 200, 400]\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1,):\n",
    "    os,prc,roc = qsar_ann_cv(Xs,y,5,10,p1l[i],0.2,0)\n",
    "    os['Data']='Scaled'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'ANN.S.0.2.'+str(p1l[i]))\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "p2l = [0, 0.1, 0.2]\n",
    "ll2 = len(p2l)\n",
    "for i in range(ll2):\n",
    "    os,prc,roc = qsar_ann_cv(Xs,y,5,10,400,p2l[i],0)\n",
    "    os['Data']='Scaled'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'ANN.R.'+str(p2l[i])+'.400')\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "metrics.to_csv('RS_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "#prc_m.to_csv('RS_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "#roc_m.to_csv('RS_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Artificial neural networks ===\n",
    "p1l = [100, 200, 400]\n",
    "ll1 = len(p1l)\n",
    "for i in range(ll1,):\n",
    "    os,prc,roc = qsar_ann_cv(Xr,y,5,10,p1l[i],0.2,0)\n",
    "    os['Data']='Reduced'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'ANN.R.0.2.'+str(p1l[i]))\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "p2l = [0, 0.1, 0.2]\n",
    "ll2 = len(p2l)\n",
    "for i in range(ll2):\n",
    "    os,prc,roc = qsar_ann_cv(Xr,y,5,10,400,p2l[i],0)\n",
    "    os['Data']='Reduced'\n",
    "    os = pd.DataFrame(os,index=[i])\n",
    "    metrics = pd.concat([metrics,os],axis=0,ignore_index=True)\n",
    "    prc2,roc2 = prc_roc(prc,roc,'ANN.R.'+str(p2l[i])+'.400')\n",
    "    prc_m = pd.concat([prc_m,prc2],axis=0,ignore_index=True)\n",
    "    roc_m = pd.concat([roc_m,roc2],axis=0,ignore_index=True)\n",
    "metrics.to_csv('RS_MULTI_MET.csv', mode='a', index=False, header=False)\n",
    "prc_m.to_csv('RS_MULTI_PRC.csv', mode='a', index=False, header=False)\n",
    "roc_m.to_csv('RS_MULTI_ROC.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8231abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
